---
layout: post
title:  "LLM 2024"
date:   2025-01-11 10:00:00 +0100
excerpt_separator: <!--more-->
tags: research
category: blog 
---

![Lego Planets](/assets/img/LLM.png)

We are currently nearing the end of an Innovate UK project called TRUST2 exploring how LLM’s can help us understand how energy is being used to control the comfort of work environments. We are also increasingly having to think about how to integrate LLM’s into our teaching environment. This post links to a couple of resources gathered in 2024.

<!--more-->

I liked this quote from an LLM primer paper Jack circulated - it talks to why we need to think about this technology from a teaching perspective:

“...real benefits to be had if this technology can be integrated in every day personal activities and in businesses and organisations to improve productivity through automation of repetitive trivial tasks, and consequently enable employees, students and researchers to dedicate more time on interesting and complex tasks” [Sandra Johnson - LLM Primer](https://arxiv.org/pdf/2412.04503). 

I have been increasingly [using various tools](https://www.iot.io/blog/2024/05/10/whirr-of-LLM.html) - but typically switching between chatgpt and gemini - and use them to quickly help me with an idea, writing the prompt and seeing the results is often the thinking circles that I need to get an idea out my head and down on paper.

The second link is to Simon Willison’s great round up of his [journey with LLM’s in 2024](https://simonwillison.net/2024/Dec/31/llms-in-2024/) - lots of great stuff in here:

- The GPT-4 barrier was comprehensively broken
- Some of those GPT-4 models run on my laptop
- LLM prices crashed, thanks to competition and increased efficiency
- Multimodal vision is common, audio and video are starting to emerge
- Voice and live camera mode are science fiction come to life
- Prompt driven app generation is a commodity already
- Universal access to the best models lasted for just a few short months
- “Agents” still haven’t really happened yet
- Evals really matter
- Apple Intelligence is bad, Apple’s MLX library is excellent
- The rise of inference-scaling “reasoning” models
- Was the best currently available LLM trained in China for less than $6m?
- The environmental impact got better
- The environmental impact got much, much worse
- The year of slop
- Synthetic training data works great
- LLMs somehow got even harder to use
- Knowledge is incredibly unevenly distributed
- LLMs need better criticism
- Everything tagged “llms” on my blog in 2024”